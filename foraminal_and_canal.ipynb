{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from fastai.vision.all import *\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CV = 5\n",
    "SEED = 777\n",
    "fold = 1\n",
    "PATCH_SIZE = 512\n",
    "patch_size = 64\n",
    "TH = .25\n",
    "SEG_TRAIN = True\n",
    "SEG = {\n",
    "    'BS':16,\n",
    "    'LR':5e-4,\n",
    "    'EPOCHS':10\n",
    "}\n",
    "INF = {\n",
    "    'BS':16,\n",
    "    'LR':1e-4,\n",
    "    'EPOCHS':10,\n",
    "    'WD':0.1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5aab3aa73942b44"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/rsna-2024-lumbar-spine-degenerative-classification/train.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "421f49ac340e4238"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "canal_diagnosis = list(filter(lambda x: x.find('canal') > -1, train.columns))\n",
    "train_canal = train[train[canal_diagnosis].isnull().values.sum(1)==0].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ec944bca11b26e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "foraminal_diagnosis = list(filter(lambda x: x.find('foraminal') > -1, train.columns))\n",
    "train_foraminal = train[train[foraminal_diagnosis].isnull().values.sum(1)==0].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c2b0bde7a3c8ba9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_meta_f = pd.read_csv('./datasets/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\n",
    "df_meta_f['series_description'].groupby(df_meta_f['series_description']).count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f08fa15d12a30e20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_coor = pd.read_csv('./datasets/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\n",
    "df_coor['condition'].groupby(df_coor['condition']).count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d476f0eda1ba6488"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_cooridnates_dataset(df:pd.core.frame.DataFrame, condition:str ):\n",
    "    resultant_df = df[df['condition']==condition][[\n",
    "        'study_id',\n",
    "        'series_id',\n",
    "        'instance_number',\n",
    "        'level',\n",
    "        'x',\n",
    "        'y'\n",
    "    ]].sort_values([\n",
    "        'study_id',\n",
    "        'series_id',\n",
    "        'level'\n",
    "    ])[[\n",
    "        'study_id',\n",
    "        'series_id',\n",
    "        'level',\n",
    "        'instance_number',\n",
    "        'x',\n",
    "        'y'    \n",
    "    ]].drop_duplicates()\n",
    "    return resultant_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4432f58c0836b072"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LF = get_cooridnates_dataset(df_coor,'Left Neural Foraminal Narrowing')\n",
    "RF = get_cooridnates_dataset(df_coor,'Right Neural Foraminal Narrowing')\n",
    "SCS = get_cooridnates_dataset(df_coor,'Spinal Canal Stenosis')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88f5c67b3e33f908"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# checking if there are no missing values in the sequence - ensuring all study ids/series ids have l1/l2 to l5/s1 levels\n",
    "(['L1/L2','L2/L3','L3/L4','L4/L5','L5/S1']*(len(LF)//5) == LF['level']).sum() == len(LF)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fa343b71cbfcb53"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LF = LF[[\n",
    "    'study_id',\n",
    "    'series_id',\n",
    "    'instance_number',\n",
    "    'x',\n",
    "    'y'    \n",
    "]]\n",
    "LF[[\n",
    "    'x_L1L2',\n",
    "    'y_L1L2',\n",
    "    'x_L2L3',\n",
    "    'y_L2L3',\n",
    "    'x_L3L4',\n",
    "    'y_L3L4',\n",
    "    'x_L4L5',\n",
    "    'y_L4L5',\n",
    "    'x_L5S1',\n",
    "    'y_L5S1',    \n",
    "]] = np.tile(LF[['x','y']].values.reshape(-1,1,5,2),(1,5,1,1)).reshape(-1,10)\n",
    "LF = LF.drop(columns=['x','y']).drop_duplicates().reset_index(drop=True)\n",
    "LF.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a296f4d07a7bdfbd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def merge_centers_with_dataset_for_na_values(df:pd.core.frame.DataFrame):\n",
    "    centers = {}\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        centers[row['study_id']]={}\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        centers[row['study_id']][row['series_id']]={'L1/L2':[],'L2/L3':[],'L3/L4':[],'L4/L5':[],'L5/S1':[]}\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        centers[row['study_id']][row['series_id']][row['level']].append([row['x'],row['y']])\n",
    "     \n",
    "    coordinates = np.zeros((len(df),10))\n",
    "    coordinates[:] = np.nan\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        for level in centers[row['study_id']][row['series_id']]:\n",
    "            if len(centers[row['study_id']][row['series_id']][level]) > 0:\n",
    "                center = np.array(centers[row['study_id']][row['series_id']][level]).mean(0)\n",
    "                coordinates[\n",
    "                    i,\n",
    "                    {'L1/L2':0, 'L2/L3':2, 'L3/L4':4, 'L4/L5':6, 'L5/S1':8}[level]:{'L1/L2':0, 'L2/L3':2, 'L3/L4':4, 'L4/L5':6, 'L5/S1':8}[level]+2\n",
    "                ] = center\n",
    "    df = df[[\n",
    "        'study_id',\n",
    "        'series_id',\n",
    "        'instance_number',\n",
    "        'x',\n",
    "        'y'    \n",
    "    ]]\n",
    "    df.loc[:,[\n",
    "        'x_L1L2',\n",
    "        'y_L1L2',\n",
    "        'x_L2L3',\n",
    "        'y_L2L3',\n",
    "        'x_L3L4',\n",
    "        'y_L3L4',\n",
    "        'x_L4L5',\n",
    "        'y_L4L5',\n",
    "        'x_L5S1',\n",
    "        'y_L5S1',    \n",
    "    ]] = coordinates\n",
    "    df = df.drop(columns=['x','y']).drop_duplicates().reset_index(drop=True)\n",
    "    df = df[df[[\n",
    "        'x_L1L2',\n",
    "        'y_L1L2',\n",
    "        'x_L2L3',\n",
    "        'y_L2L3',\n",
    "        'x_L3L4',\n",
    "        'y_L3L4',\n",
    "        'x_L4L5',\n",
    "        'y_L4L5',\n",
    "        'x_L5S1',\n",
    "        'y_L5S1',    \n",
    "    ]].isnull().values.sum(1)==0].reset_index(drop=True)\n",
    "    df.tail()\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc49132ecb32222a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "RF = merge_centers_with_dataset_for_na_values(RF)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1832fc510617aab4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def merge_coordinates_with_main_dataset(df:pd.core.frame.DataFrame, train:pd.core.frame.DataFrame, condition:str):\n",
    "    diagnosis = list(filter(lambda x: x.find(condition) > -1, train.columns))\n",
    "    df = df.merge(train[['study_id']+diagnosis], left_on='study_id', right_on='study_id')\n",
    "    df.tail()\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df1e70847b54ddfd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LF = merge_coordinates_with_main_dataset(LF,train_foraminal,'left_neural')\n",
    "RF = merge_coordinates_with_main_dataset(RF,train_foraminal,'right_neural')\n",
    "SCS = merge_coordinates_with_main_dataset(SCS,train_canal,'canal')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd4fdeda238b8786"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_diagnosis_list_and_renamed_columns(df:pd.core.frame.DataFrame, orientation:str):\n",
    "    diagnosis = list(filter(lambda x: x.find(orientation) > -1, df.columns))\n",
    "    diagnosis = {x:x[len(orientation)+1:] for x in diagnosis}\n",
    "    df = df.rename(columns=diagnosis)\n",
    "    return df\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be495c30d81db74a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LF = get_diagnosis_list_and_renamed_columns(LF,'left')\n",
    "RF = get_diagnosis_list_and_renamed_columns(RF,'right')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "690cc23fe05afcd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "FDF = pd.concat([LF,RF],axis=0,ignore_index=True)\n",
    "FDF = FDF.merge(df_meta_f[['series_id','series_description']], left_on='series_id', right_on='series_id')\n",
    "FDF.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52ef3ecda04ae56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def define_cross_validation_index(df:pd.core.frame.DataFrame):\n",
    "    v,c = np.unique(df['study_id'],return_counts=True)\n",
    "    plt.plot(v,c,'.')\n",
    "    L = len(v)\n",
    "    S = L/CV\n",
    "    fold_indices = list(np.rint(np.arange(CV)*S).astype(int))+[L]\n",
    "    for i in range(5):\n",
    "#         print(len(v[fold_indices[i]:fold_indices[i+1]]))\n",
    "        df.loc[df['study_id'].isin(v[fold_indices[i]:fold_indices[i+1]]),'series_description'] = i+1\n",
    "    df.tail()\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "691da3f1fda048ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "FDF = define_cross_validation_index(FDF)\n",
    "SCS = define_cross_validation_index(SCS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dabc2f0677f45ab7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'Normal/Mild':0,\n",
    "    'Moderate':1,\n",
    "    'Severe':2\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eeb86879ac38960"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coor = [\n",
    "    'x_L1L2',\n",
    "    'y_L1L2',\n",
    "    'x_L2L3',\n",
    "    'y_L2L3',\n",
    "    'x_L3L4',\n",
    "    'y_L3L4',\n",
    "    'x_L4L5',\n",
    "    'y_L4L5',\n",
    "    'x_L5S1',\n",
    "    'y_L5S1',    \n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5032ddcb79af2e28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Segmentation Dataset </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef6f9a3660932913"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_image_and_centers(image,centers,alpha):\n",
    "    '''\n",
    "    # Randomly flip the image horizontally.\n",
    "    if random.random() > .5:\n",
    "      if random.random() > 1 - alpha:\n",
    "        image = image.flip(-1)\n",
    "        centers[:,0] = PATCH_SIZE - centers[:,0]\n",
    "    # Randomly flip the image vertically.\n",
    "    if random.random() > 0.5:\n",
    "      if random.random() > 1 - alpha:\n",
    "        image = image.flip(-2)\n",
    "        centers[:,1] = PATCH_SIZE - centers[:,1]\n",
    "  \n",
    "    if random.random() > 1 - alpha:\n",
    "      if random.random() > .5:\n",
    "    #   Randomly flip the image\n",
    "    #   Wich axis?\n",
    "        axis = np.random.randint(2)\n",
    "        image = image.flip(axis+1)\n",
    "        centers[:,-1-axis] = PATCH_SIZE - centers[:,-1-axis]\n",
    "    '''\n",
    "#   Randomly rotate the image.\n",
    "    angle = torch.as_tensor(random.uniform(-180, 180)*alpha)\n",
    "    image = torchvision.transforms.functional.rotate(image,angle.item())\n",
    "#   https://discuss.pytorch.org/t/rotation-matrix/128260\n",
    "    angle = -angle*math.pi/180\n",
    "    s = torch.sin(angle)\n",
    "    c = torch.cos(angle)\n",
    "    rot = torch.stack([\n",
    "        torch.stack([c, s]),\n",
    "        torch.stack([-s, c])\n",
    "      ])\n",
    "    centers = ((centers.cpu() - PATCH_SIZE//2) @ rot) + PATCH_SIZE//2\n",
    "\n",
    "    return image,centers\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cb727af71c7195c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class T1Dataset(Dataset):\n",
    "    def __init__(self, df, VALID=False, alpha=0):\n",
    "        self.data = df\n",
    "        self.VALID = VALID\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        target = self.data.columns[-6:-1]\n",
    "        centers = torch.as_tensor([x for x in row[coor]]).view(5,2).float()\n",
    "        \n",
    "        sample = './datasets/rsna-2024-lumbar-spine-degenerative-classification/train_images/'\n",
    "        sample1 = sample+str(row['study_id'])+'/'+str(row['series_id'])+'/'+str(row['instance_number'])+'.dcm'\n",
    "        \n",
    "        image = pydicom.dcmread(sample1).pixel_array\n",
    "        H,W = image.shape\n",
    "#       By plane resizing I've been distorting the proportions\n",
    "        if H > W:\n",
    "            d = W\n",
    "            if not self.VALID:\n",
    "                h = int((H - d)*(.5 + self.alpha*(.5 - np.random.rand())))\n",
    "            else:\n",
    "                h = (H - d)//2\n",
    "            image = image[h:h+d]\n",
    "            centers[:,1] -= h\n",
    "            H = W\n",
    "        elif H < W:\n",
    "            d = H\n",
    "            if not self.VALID:\n",
    "                w = int((W - d)*(.5 + self.alpha*(.5 - np.random.rand())))\n",
    "            else:\n",
    "                w = (W - d)//2\n",
    "            image = image[:,w:w+d]\n",
    "            centers[:,0] -= w\n",
    "            W = H\n",
    "        image = cv2.resize(image,(PATCH_SIZE,PATCH_SIZE))\n",
    "        image = torch.as_tensor(image/np.max(image)).unsqueeze(0).float()\n",
    "        \n",
    "        label = torch.as_tensor([labels[x] for x in row[target]])\n",
    "        \n",
    "        centers[:,0] = centers[:,0]*PATCH_SIZE/W\n",
    "        centers[:,1] = centers[:,1]*PATCH_SIZE/H\n",
    "\n",
    "        if not self.VALID: image,centers = augment_image_and_centers(image,centers,self.alpha)\n",
    "\n",
    "        return image.to(device),[label.to(device),centers.to(device)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85328f02beef6e6f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4950dafc8c0f9b13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "idx_map = torch.stack([torch.arange(PATCH_SIZE)]*PATCH_SIZE).to(device)\n",
    "idx_map = torch.stack([idx_map,idx_map.T]).view(1,1,2,PATCH_SIZE,PATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcd99f022bd1aa73"
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### Segmentation UNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b190e45567f5eab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class myUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myUNet, self).__init__()\n",
    "\n",
    "        self.UNet = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            classes=5,\n",
    "            in_channels=1\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self,X):\n",
    "        x = self.UNet(X)\n",
    "#       MinMaxScaling along the class plane to generate a heatmap\n",
    "        min_values = x.view(-1,5,PATCH_SIZE*PATCH_SIZE).min(-1)[0].view(-1,5,1,1) # Bug, I've been MinMaxScaling with the wrong values\n",
    "        max_values = x.view(-1,5,PATCH_SIZE*PATCH_SIZE).max(-1)[0].view(-1,5,1,1)\n",
    "        x = (x - min_values)/(max_values - min_values)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4399f5cca7db61d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Segmentation Loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d71af448e1b22fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class myLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha=.5\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def clone(self):\n",
    "        return myLoss(self.alpha)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            y,# Predictions\n",
    "            t # Targets\n",
    "        ):\n",
    "        mask_pred = y\n",
    "        _,mask_true = t\n",
    "#       The heatmap Loss as the distance between the predicted Normal and the ideal one\n",
    "#       Let's define the ideal heatmaps as the Normal distributions\n",
    "#       centered on the diagnostic centers with s2 = PATCH_SIZE/8\n",
    "        s2 = s2 = torch.as_tensor([PATCH_SIZE/8]*5)\n",
    "#       Then the corresponding alphas and normalization constants would be\n",
    "        A = -1/(2*s2).to(device)\n",
    "        K = 1/torch.sqrt(2*math.pi*s2).to(device)\n",
    "#       Predicted heatmaps rescaling\n",
    "        mask_pred = mask_pred*K.view(1,5,1,1)\n",
    "#       Ideal heatmaps\n",
    "        mask = idx_map - mask_true.view(-1,5,2,1,1)\n",
    "        mask = torch.exp((A.view(-1,5,1,1,1)*mask*mask).sum(2))*K.view(-1,5,1,1)\n",
    "#       Distance\n",
    "        D = 1 - ((mask*mask_pred).sum())**2/((mask*mask).sum()*(mask_pred*mask_pred).sum())\n",
    "        \n",
    "        return D"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b02be257ce1122b5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_segmentation(df:pd.core.frame.DataFrame,condition:str,folds:int):\n",
    "    \n",
    "    def nt(nmin,nmax,tcur,tmax):\n",
    "        return (nmax - .5*(nmax-nmin)*(1+np.cos(tcur*np.pi/tmax))).astype(np.float32)\n",
    "\n",
    "    plt.plot(nt(0,1,np.arange(SEG['EPOCHS']),SEG['EPOCHS']))\n",
    "    plt.show()\n",
    "\n",
    "    # callback to update alpha during training\n",
    "    def cb(self):\n",
    "        alpha = torch.as_tensor(nt(.25,1,learn.train_iter,SEG['EPOCHS']*n_iter))\n",
    "        learn.dls.train_ds.alpha = alpha\n",
    "    alpha_cb = Callback(before_batch=cb)#\n",
    "    target = df.columns[-6:-1]\n",
    "    for fold in range(2,folds+1):\n",
    "        tdf = df[df['series_description'] != fold]\n",
    "        vdf = df[df['series_description'] == fold]\n",
    "\n",
    "        tds = T1Dataset(tdf)\n",
    "        vds = T1Dataset(vdf,VALID=True)\n",
    "        tdl = torch.utils.data.DataLoader(tds, batch_size=SEG['BS'], shuffle=True, drop_last=True)\n",
    "        vdl = torch.utils.data.DataLoader(vds, batch_size=SEG['BS'], shuffle=False)\n",
    "\n",
    "        if SEG_TRAIN:\n",
    "            seed_everything(SEED)\n",
    "\n",
    "            dls = DataLoaders(tdl,vdl)\n",
    "\n",
    "            n_iter = len(tds)//SEG['BS']\n",
    "\n",
    "            model = myUNet()\n",
    "            learn = Learner(\n",
    "                dls,\n",
    "                model,\n",
    "                lr=SEG['LR'],\n",
    "                loss_func=myLoss(alpha=0.5),\n",
    "                cbs=[\n",
    "                    ShowGraphCallback(),\n",
    "                    alpha_cb\n",
    "                ]\n",
    "            )\n",
    "            learn.fit_one_cycle(SEG['EPOCHS'],lr_max=5e-4, wd=0.1)\n",
    "        #   learn.fit(SEG['EPOCHS'])\n",
    "            torch.save(model,'SEG_'+condition+'_'+str(fold))\n",
    "            del tdl,vdl,dls,model,learn\n",
    "            gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2a1d8bf4b22da9d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_segmentation(FDF,'foraminal',CV)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a363516239a00f4c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_segmentation(FDF,'canal',CV)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ff20353852bb47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "foraminal_seg_models = []\n",
    "for i in range(1,6):\n",
    "    foraminal_seg_models.append(torch.load('./datasets/foraminal-segmentation-models/SEG_foraminal_'+str(i)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f8dbf4ab0a79e1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "canal_seg_models = []\n",
    "for i in range(1,6):\n",
    "    canal_seg_models.append(torch.load('./datasets/canal-segmentation-models/SEG_canal_'+str(i)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b4199848c39930a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model1 = torch.load('./datasets/foraminal-segmentation-models/SEG_foraminal_1')\n",
    "# i = np.random.randint(len(vds))\n",
    "# img,centers = vds.__getitem__(i)\n",
    "# OUT = model1(img.unsqueeze(0)).cpu().detach()\n",
    "# centers = centers[1].cpu().long()\n",
    "# print(i)\n",
    "# fig, axes1 = plt.subplots(1, 5, figsize=(10,10))\n",
    "# fig, axes2 = plt.subplots(1, 5, figsize=(10,10))\n",
    "# for k in range(5):\n",
    "#     image = img[0].cpu() + OUT[0,k].cpu()\n",
    "#     c = (OUT[0,k].unsqueeze(0)*idx_map[0,0].cpu()).sum(-1).sum(-1)\n",
    "#     d = OUT[0,k].sum()\n",
    "#     c = c/d\n",
    "#     Y,X = centers.cpu().long()[k]\n",
    "#     YY,XX = c.long()\n",
    "#     print(Y,X)\n",
    "#     print(YY,XX)\n",
    "#     for y in range(height):\n",
    "#         for x in range(width):\n",
    "#             # see if we're close to (x-a)**2 + (y-b)**2 == r**2\n",
    "#             if abs((x-A)**2 + (y-B)**2 - r**2) < EPSILON**2:\n",
    "#                 image[x+X-5,y+Y-5] = 0\n",
    "#     axes1[k].imshow(image)\n",
    "#     axes2[k].imshow(image[XX-64:XX+64,YY-64:YY+64])\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd8262c0b2dcbb22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f70d0cd7f65c4fb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_image(image,alpha):\n",
    "    # Randomly rotate the image.\n",
    "    angle = torch.as_tensor(random.uniform(-180, 180)*alpha)\n",
    "    image = torchvision.transforms.functional.rotate(image,angle.item())\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T19:36:55.692394Z",
     "start_time": "2024-11-25T19:36:55.681779Z"
    }
   },
   "id": "2f3a2e3f3230b565",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ViT_T1_Dataset(Dataset):\n",
    "    def __init__(self, df, UNet, Unet_Models, VALID=False, P=patch_size, alpha=0):\n",
    "        self.data = df\n",
    "        self.UNet = UNet\n",
    "        self.unet_models = Unet_Models\n",
    "        self.VALID = VALID\n",
    "        self.P = P\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        \n",
    "        sample = './datasets/rsna-2024-lumbar-spine-degenerative-classification/train_images/'\n",
    "        sample1 = sample+str(row['study_id'])+'/'+str(row['series_id'])+'/'+str(row['instance_number'])+'.dcm'\n",
    "        centers = torch.as_tensor([x for x in row[coor]]).view(5,2).float()\n",
    "        image = pydicom.dcmread(sample1).pixel_array\n",
    "        H,W = image.shape\n",
    "#       By plane resizing I've been distorting the proportions\n",
    "        if H > W:\n",
    "            d = W\n",
    "            h = (H - d)//2\n",
    "            image = image[h:h+d]\n",
    "            centers[:,1] -= h\n",
    "            H = W\n",
    "        elif H < W:\n",
    "            d = H\n",
    "            w = (W - d)//2\n",
    "            image = image[:,w:w+d]\n",
    "            centers[:,0] -= w\n",
    "            W = H\n",
    "        image = cv2.resize(image,(PATCH_SIZE,PATCH_SIZE))\n",
    "        image = torch.as_tensor(image/np.max(image)).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "        OUT = 0\n",
    "        with torch.no_grad():\n",
    "                for rot in [0,1,2,3]:\n",
    "                        OUT += torch.rot90(self.UNet(torch.rot90(image,rot,dims=[-2, -1])),-rot,dims=[-2, -1])\n",
    "\n",
    "        OUT = (OUT/4 > 0.25)[0]\n",
    "        c = (OUT.unsqueeze(1)*idx_map[0]).view(5,2,PATCH_SIZE*PATCH_SIZE).sum(-1).float()\n",
    "        d = OUT.view(5,PATCH_SIZE*PATCH_SIZE).sum(-1).float()\n",
    "        m = d > 0\n",
    "        c[m] = (c[m]/d[m].unsqueeze(-1)).float()\n",
    "#         c[~m] = self.P # I have to find a better solution\n",
    "        c[~m] = self.P\n",
    "        c[c < 64] = torch.nan\n",
    "        c[c > 448] = torch.nan\n",
    "        c_mean = torch.nanmean(c, dim=0)\n",
    "        mask = torch.isnan(c)\n",
    "        c[mask[:,0],0] = c_mean[0]\n",
    "        c[mask[:,1],1] = c_mean[1]\n",
    "        c = c.long()\n",
    "#         print(row['study_id'],row['series_id'],row['instance_number'])\n",
    "        image = torch.stack([image[\n",
    "            0,\n",
    "            0,\n",
    "            xy[1]-self.P//2:xy[1]+self.P-self.P//2,\n",
    "            xy[0]-self.P//2:xy[0]+self.P-self.P//2\n",
    "        ] for xy in c])\n",
    "#         print(image.shape,c,mask,c_mean)\n",
    "        if not self.VALID: \n",
    "            \n",
    "            image = augment_image(image,self.alpha)\n",
    "        \n",
    "        label = torch.as_tensor([labels[x] for x in row[target]])\n",
    "\n",
    "        return [image.to(device),~m.to(device)],[label.to(device),~m.to(device)]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1abbbdb55ecf1a65"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[...,None] * emb[None,...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class myViT(nn.Module):\n",
    "    def __init__(self, dim=512, depth=12, head_size=128, **kwargs):\n",
    "        super().__init__()\n",
    "        CNN = torchvision.models.resnet18(weights='DEFAULT')\n",
    "        W = nn.Parameter(CNN.conv1.weight.sum(1, keepdim=True))\n",
    "        CNN.conv1 = nn.Conv2d(1, patch_size, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        CNN.conv1.weight = W\n",
    "        CNN.fc = nn.Identity()\n",
    "        self.emb = CNN.to(device)\n",
    "        self.pos_enc = nn.Parameter(SinusoidalPosEmb(dim)(torch.arange(5, device=device).unsqueeze(0)))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n",
    "                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True, device=device), depth)\n",
    "        self.proj_out = nn.Linear(dim,3).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(\"x: \",x)\n",
    "        x,mask = x\n",
    "        x = self.emb(x.view(-1,1,patch_size,patch_size))\n",
    "        x = x.view(-1,5,512)\n",
    "        x = x + self.pos_enc\n",
    "        x = self.transformer(x,src_key_padding_mask=mask)\n",
    "        x = self.proj_out(x.view(-1,512))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "564a8924c52038e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference VIT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5b1d7c73cbf4f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfcedd9732cd8aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference Loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8baa27b4c561420"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def myLoss(preds,target):\n",
    "    target,mask = target\n",
    "    target = target[~mask]\n",
    "    preds = preds[~mask.view(-1)]\n",
    "    return nn.CrossEntropyLoss(weight=torch.as_tensor([1.,2.,4.]).to(device))(preds,target)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "feac90755e08e6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d802e447796a50f3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def nt(nmin,nmax,tcur,tmax):\n",
    "    return (nmax - .5*(nmax-nmin)*(1+np.cos(tcur*np.pi/tmax))).astype(np.float32)\n",
    "\n",
    "plt.plot(nt(0,1,np.arange(INF['EPOCHS']),INF['EPOCHS']))\n",
    "plt.show()\n",
    "\n",
    "# callback to update alpha during training\n",
    "def cb(self):\n",
    "    alpha = torch.as_tensor(nt(.25,1,learn.train_iter,INF['EPOCHS']*n_iter))\n",
    "    learn.dls.train_ds.alpha = alpha\n",
    "alpha_cb = Callback(before_batch=cb)#"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bab0db37afb807a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Foraminal Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "450acefda6dfac83"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target = FDF.columns[-6:-1]\n",
    "target"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84cb4946d96818b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for fold in range(1,6):\n",
    "    seed_everything(SEED)\n",
    "    tdf = FDF[FDF['series_description'] != fold]\n",
    "    vdf = FDF[FDF['series_description'] == fold]\n",
    "    tds = ViT_T1_Dataset(tdf,foraminal_seg_models[fold-1],foraminal_seg_models)\n",
    "    vds = ViT_T1_Dataset(vdf,foraminal_seg_models[fold-1],foraminal_seg_models,VALID=True)\n",
    "    tdl = torch.utils.data.DataLoader(tds, batch_size=INF['BS'], shuffle=True, drop_last=True)\n",
    "    vdl = torch.utils.data.DataLoader(vds, batch_size=INF['BS'], shuffle=False)\n",
    "\n",
    "    dls = DataLoaders(tdl,vdl)\n",
    "\n",
    "    n_iter = len(tds)//INF['BS']\n",
    "\n",
    "    model = myViT()\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        lr=1e-4,\n",
    "        loss_func=myLoss,\n",
    "        cbs=[\n",
    "            ShowGraphCallback(),\n",
    "            alpha_cb,\n",
    "            GradientClip(3.0)\n",
    "        ]\n",
    "    )\n",
    "    learn.fit_one_cycle(INF['EPOCHS'],lr_max=1e-4,wd=INF['WD'])\n",
    "    torch.save(model,'Final_ViT_foraminal_'+str(fold))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d605b733b9ed19a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sklearn\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for [X,mask],[Y,mask] in tqdm(vdl):\n",
    "        y_true.extend(Y[~mask].cpu().tolist())\n",
    "        y_pred.extend(torch.argmax(model([X,mask]),-1)[~mask.view(-1)].cpu().tolist())\n",
    "\n",
    "sklearn.metrics.confusion_matrix(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c8dee31c28ac231"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del y_true, y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca5242429f399dba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Canal Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a239b6437726847"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target = SCS.columns[-6:-1]\n",
    "target"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aee802f2fcbaa8ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for fold in range(1,6):\n",
    "    seed_everything(SEED)\n",
    "    tdf = SCS[SCS['series_description'] != fold]\n",
    "    vdf = SCS[SCS['series_description'] == fold]\n",
    "    tds = ViT_T1_Dataset(tdf, foraminal_seg_models[fold - 1], foraminal_seg_models)\n",
    "    vds = ViT_T1_Dataset(vdf, foraminal_seg_models[fold - 1], foraminal_seg_models, VALID=True)\n",
    "    tdl = torch.utils.data.DataLoader(tds, batch_size=INF['BS'], shuffle=True, drop_last=True)\n",
    "    vdl = torch.utils.data.DataLoader(vds, batch_size=INF['BS'], shuffle=False)\n",
    "\n",
    "    dls = DataLoaders(tdl, vdl)\n",
    "\n",
    "    n_iter = len(tds) // INF['BS']\n",
    "\n",
    "    model = myViT()\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        lr=1e-4,\n",
    "        loss_func=myLoss,\n",
    "        cbs=[\n",
    "            ShowGraphCallback(),\n",
    "            alpha_cb,\n",
    "            GradientClip(3.0)\n",
    "        ]\n",
    "    )\n",
    "    learn.fit_one_cycle(INF['EPOCHS'], lr_max=1e-4, wd=INF['WD'])\n",
    "    torch.save(model, 'Final_ViT_foraminal_' + str(fold))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b42dade3dcc661c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for [X, mask], [Y, mask] in tqdm(vdl):\n",
    "        y_true.extend(Y[~mask].cpu().tolist())\n",
    "        y_pred.extend(torch.argmax(model([X, mask]), -1)[~mask.view(-1)].cpu().tolist())\n",
    "\n",
    "sklearn.metrics.confusion_matrix(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3052c3d6379ac78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
