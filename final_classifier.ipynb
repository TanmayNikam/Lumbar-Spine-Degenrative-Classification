{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from fastai.vision.all import *\n",
    "import sys\n",
    "!pip install segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60cf3ffa5dd1c96d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rd = './datasets/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "185284541f33958f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\n",
    "# df = pd.read_csv(\"./datasets/rsna-lsdc-2024-submission-debug-dataset/debug/test_series_descriptions.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24cce281aa495592"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "study_ids = list(df['study_id'].unique())\n",
    "sample_sub = pd.read_csv(\"./datasets/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv\")\n",
    "LABELS = list(sample_sub.columns[1:])\n",
    "LABELS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35bc06346e64cf8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "NEURAL_FORAMINAL_CONDITION = [\n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "]\n",
    "\n",
    "SPINAL_CANAL_CONDITION = [\n",
    "    'spinal_canal_stenosis'\n",
    "]\n",
    "\n",
    "SUBARTICULAR_CONDITIONS = [\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]\n",
    "PATCH_SIZE = 512\n",
    "patch_size = 128\n",
    "Lmax=36"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2525856e0b6a5e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class myUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(foraminalunet, self).__init__()\n",
    "\n",
    "        self.UNet= smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            encoder_weights=None,\n",
    "            classes=5,\n",
    "            in_channels=1\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self,X):\n",
    "        x = self.UNet(X)\n",
    "#       MinMaxScaling along the class plane to generate a heatmap\n",
    "        min_values = x.view(-1,5,PATCH_SIZE*PATCH_SIZE).min(-1)[0].view(-1,5,1,1) # Bug, I've been MinMaxScaling with the wrong values\n",
    "        max_values = x.view(-1,5,PATCH_SIZE*PATCH_SIZE).max(-1)[0].view(-1,5,1,1)\n",
    "        x = (x - min_values)/(max_values - min_values)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58729758cb6c0cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[...,None] * emb[None,...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class myViT(nn.Module):\n",
    "    def __init__(self, dim=512, depth=12, head_size=128, **kwargs):\n",
    "        super().__init__()\n",
    "        CNN = torchvision.models.resnet34(weights='DEFAULT')\n",
    "        W = nn.Parameter(CNN.conv1.weight.sum(1, keepdim=True))\n",
    "        CNN.conv1 = nn.Conv2d(1, patch_size, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        CNN.conv1.weight = W\n",
    "        CNN.fc = nn.Identity()\n",
    "        self.emb = CNN.to(device)\n",
    "        self.pos_enc = nn.Parameter(SinusoidalPosEmb(dim)(torch.arange(5, device=device).unsqueeze(0)))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n",
    "                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True, device=device), depth)\n",
    "        self.proj_out = nn.Linear(dim,3).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         print(\"x: \",x)\n",
    "        x,mask = x\n",
    "        x = self.emb(x.view(-1,1,patch_size,patch_size))\n",
    "        x = x.view(-1,5,512)\n",
    "        x = x + self.pos_enc\n",
    "        x = self.transformer(x,src_key_padding_mask=mask)\n",
    "        x = self.proj_out(x.view(-1,512))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7755e7a098f30bae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_image_for_canal_foraminal(path ,unet, patch_size, TH=0.5):\n",
    "    idx_map = torch.stack([torch.arange(PATCH_SIZE)]*PATCH_SIZE).to(device)\n",
    "    idx_map = torch.stack([idx_map,idx_map.T]).view(1,1,2,PATCH_SIZE,PATCH_SIZE)\n",
    "    image = pydicom.dcmread(path).pixel_array\n",
    "    H,W = image.shape\n",
    "#       By plane resizing I've been distorting the proportions\n",
    "    if H > W:\n",
    "        d = W\n",
    "        h = (H - d)//2\n",
    "        image = image[h:h+d]\n",
    "        H = W\n",
    "    elif H < W:\n",
    "        d = H\n",
    "        w = (W - d)//2\n",
    "        image = image[:,w:w+d]\n",
    "        W = H\n",
    "    image = cv2.resize(image,(PATCH_SIZE,PATCH_SIZE))\n",
    "    image = torch.as_tensor(image/np.max(image)).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "    OUT = 0\n",
    "    with torch.no_grad():\n",
    "            for rot in [0,1,2,3]:\n",
    "                    OUT += torch.rot90(unet(torch.rot90(image,rot,dims=[-2, -1])),-rot,dims=[-2, -1])\n",
    "\n",
    "    OUT = (OUT/4 > TH)[0]\n",
    "    c = (OUT.unsqueeze(1)*idx_map[0]).view(5,2,PATCH_SIZE*PATCH_SIZE).sum(-1).float()\n",
    "    d = OUT.view(5,PATCH_SIZE*PATCH_SIZE).sum(-1).float()\n",
    "    m = d > 0\n",
    "    c[m] = (c[m]/d[m].unsqueeze(-1)).float()\n",
    "    c[~m] = 0 # I have to find a better solution\n",
    "    c[c < 64] = torch.nan\n",
    "    c[c > 448] = torch.nan\n",
    "    c_mean = torch.nanmean(c, dim=0)\n",
    "    mask = torch.isnan(c)\n",
    "    c[mask[:,0],0] = c_mean[0]\n",
    "    c[mask[:,1],1] = c_mean[1]\n",
    "    c = c.long()\n",
    "    image = torch.stack([image[\n",
    "        0,\n",
    "        0,\n",
    "        xy[1]-patch_size//2:xy[1]+patch_size-patch_size//2,\n",
    "        xy[0]-patch_size//2:xy[0]+patch_size-patch_size//2\n",
    "    ] for xy in c])\n",
    "\n",
    "    return [image.to(device),~m.to(device)]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17834ee37e330131"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AxialUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AxialUnet, self).__init__()\n",
    "\n",
    "        self.UNet = smp.Unet(\n",
    "            encoder_name=\"resnet34\",\n",
    "            classes=2,\n",
    "            in_channels=1\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self,X):\n",
    "        x = self.UNet(X)\n",
    "#       MinMaxScaling along the class plane to generate a heatmap\n",
    "        min_values = x.view(-1,2,PATCH_SIZE*PATCH_SIZE).min(-1)[0].view(-1,2,1,1) # Bug, I've been MinMaxScaling with the wrong values\n",
    "        max_values = x.view(-1,2,PATCH_SIZE*PATCH_SIZE).max(-1)[0].view(-1,2,1,1)\n",
    "        x = (x - min_values)/(max_values - min_values)\n",
    "        \n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f163c02b0c2d98"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def input_image_resizing(image):\n",
    "    H,W = image.shape\n",
    "#       By plane resizing I've been distorting the proportions\n",
    "    if H > W:\n",
    "        d = W\n",
    "        h = int((H - d)*(.5 + .5*(.5 - np.random.rand())))\n",
    "        image = image[h:h+d]\n",
    "        H = W\n",
    "    elif H < W:\n",
    "        d = H\n",
    "        w = int((W - d)*(.5 + .5*(.5 - np.random.rand())))\n",
    "        image = image[:,w:w+d]\n",
    "        W = H\n",
    "    image = cv2.resize(image,(PATCH_SIZE,PATCH_SIZE))\n",
    "    image = torch.as_tensor(image/np.max(image)).unsqueeze(0).float()\n",
    "    return image\n",
    "\n",
    "def create_coords(unet_model, images):\n",
    "    idx_map = torch.stack([torch.arange(PATCH_SIZE)]*PATCH_SIZE).to(device)\n",
    "    idx_map = torch.stack([idx_map,idx_map.T]).view(1,1,2,PATCH_SIZE,PATCH_SIZE)\n",
    "    slices = list(np.arange(len(images)))\n",
    "    slices.sort(key=lambda k:int(images[k].split('/')[-1].replace('.dcm','')))\n",
    "    images = np.array(images)[slices]\n",
    "    images = [pydicom.dcmread(img).pixel_array for img in images]\n",
    "    coords = []\n",
    "    for img in images:\n",
    "        img = input_image_resizing(img)\n",
    "        OUT = unet_model(img.to(device).unsqueeze(0)).cpu().detach()\n",
    "        for k in range(2):\n",
    "            c = (OUT[0,k].unsqueeze(0)*idx_map[0,0].cpu()).sum(-1).sum(-1)\n",
    "            d = OUT[0,k].sum()\n",
    "            c = c/d\n",
    "            YY,XX = c.float()\n",
    "            coords.append(torch.tensor(np.array([YY,XX])))\n",
    "    coords_mean = []\n",
    "    for i in range(0,len(coords),2):\n",
    "        coords_mean.append(torch.mean(torch.stack([coords[i],coords[i+1]]),axis=0))\n",
    "    return coords, coords_mean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2ee06bffa8af899"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_images_for_axial_slice_labelling(coord,images):\n",
    "#     print(coord)\n",
    "    resize = torchvision.transforms.Resize((PATCH_SIZE,PATCH_SIZE),antialias=True)\n",
    "    c = torch.stack(coord)\n",
    "    slices = list(np.arange(len(images)))\n",
    "    slices.sort(key=lambda k:int(images[k].split('/')[-1].replace('.dcm','')))\n",
    "    instance_numbers = torch.as_tensor([int(x.split('/')[-1].replace('.dcm','')) for x in images])[slices]\n",
    "    images = np.array(images)[slices]\n",
    "#     images = [pydicom.dcmread(img).pixel_array for img in images]\n",
    "    D = len(images)\n",
    "    \n",
    "    c[c < 64] = torch.nan\n",
    "    c[c > 448] = torch.nan\n",
    "    \n",
    "    if D > Lmax:\n",
    "        slices = np.rint(torch.arange(Lmax)*D/Lmax).long()\n",
    "        images = images[slices]\n",
    "        c = c[slices]\n",
    "    elif D < Lmax:\n",
    "        N = Lmax//D + 1\n",
    "        slices = torch.repeat_interleave(torch.arange(D), N) \n",
    "        slices = slices[np.rint(torch.arange(Lmax)*(D*N)/Lmax).long()]\n",
    "        images = images[slices]\n",
    "        c = c[slices]\n",
    "\n",
    "    images = [torch.as_tensor(pydicom.dcmread(img).pixel_array.astype('float32')) for img in images]\n",
    "    shapes = [img.shape for img in images]\n",
    "    H,W = np.array(shapes).max(0)\n",
    "\n",
    "    image = torch.concat([torch.nn.functional.pad(\n",
    "        images[k].unsqueeze(0),(\n",
    "            (W - shapes[k][-1])//2,\n",
    "            (W - shapes[k][-1]) - (W - shapes[k][-1])//2,\n",
    "            (H - shapes[k][-2])//2,\n",
    "            (H - shapes[k][-2]) - (H - shapes[k][-2])//2\n",
    "        ),\n",
    "    mode='reflect') for k in range(len(images))]).float()\n",
    "\n",
    "    if H > W:\n",
    "        d = W\n",
    "        h = (H - d)//2\n",
    "        image = image[:,h:h+d]\n",
    "        H = W\n",
    "    elif H < W:\n",
    "        d = H\n",
    "        w = (W - d)//2\n",
    "        image = image[:,:,w:w+d]\n",
    "        W = H\n",
    "        \n",
    "    image = resize(image/image.max()).float().unsqueeze(1).to(device)\n",
    "    \n",
    "\n",
    "    mask = torch.isnan(c)\n",
    "    c_mean = torch.nanmean(c,0)\n",
    "    c[mask[:,0],0] = c_mean[0]\n",
    "    c[mask[:,1],1] = c_mean[1]\n",
    "    c = c.long()\n",
    "    image = torch.stack([\n",
    "        image[\n",
    "            i,\n",
    "            :,\n",
    "            c[i,1]-patch_size//2:c[i,1]+patch_size-patch_size//2,\n",
    "            c[i,0]-patch_size//2:c[i,0]+patch_size-patch_size//2\n",
    "        ] for i in range(len(images))\n",
    "    ])\n",
    "    return image.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4109277cf492feb1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim=16, M=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.M = M\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.M) / half_dim\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n",
    "        emb = x[...,None] * emb[None,...]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class Axial_ViT(nn.Module):\n",
    "    def __init__(self, ENCODER, dim=512, depth=24, head_size=64, **kwargs):\n",
    "        super().__init__()\n",
    "        self.ENCODER = ENCODER\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(output_size=1).to(device)\n",
    "        self.slices_enc = nn.Parameter(SinusoidalPosEmb(dim)(torch.arange(Lmax, device=device).unsqueeze(0)))\n",
    "        self.slices_transformer = nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n",
    "                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True, device=device), depth)\n",
    "        self.proj_out = nn.Linear(dim,5).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.ENCODER(x.view(-1,1,patch_size,patch_size))[-1]\n",
    "        x = self.AvgPool(x)\n",
    "        x = x.view(-1,Lmax,512)\n",
    "        x = x + self.slices_enc\n",
    "        x = self.slices_transformer(x)#,src_key_padding_mask=slices_mask)\n",
    "        x = self.proj_out(x.view(-1,512)).view(-1,Lmax,5).permute(0,2,1)\n",
    "#       MinMaxScaling along the class plane to generate a heatmap\n",
    "        min_values = x.min(-1)[0].view(-1,5,1)\n",
    "        max_values = x.max(-1)[0].view(-1,5,1)\n",
    "        x = (x - min_values)/(max_values - min_values)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3638097cb96bf2ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Lmax=36\n",
    "indices = np.arange(Lmax)\n",
    "def get_axial_slices(X):\n",
    "#     for f in [1,2,3,4,5]:\n",
    "#         model = torch.load('./datasets/rsna-models/axial_T2_levels_'+str(f))\n",
    "#         model.eval()\n",
    "# #         dl = torch.utils.data.DataLoader(Axial_ViT_Dataset(train,f,VALID=True,INFERENCE=True), batch_size=BS, shuffle=False)\n",
    "\n",
    "#         popt = []\n",
    "#         with torch.no_grad():\n",
    "#             y_pred = (model(X)+model(X.flip(1)).flip(-1)).cpu()/2\n",
    "#             x0 = torch.argmax(y_pred,-1)\n",
    "\n",
    "#             for i in range(len(y_pred)):\n",
    "#                 for k in range(5):\n",
    "#                     popt = popt + list(curve_fit(func, indices, y_pred[i][k],[x0[i][k],1],maxfev = 9999)[0])\n",
    "#         popt = torch.as_tensor(popt).view(-1,5,2).permute(0,2,1).reshape(-1,2*5)\n",
    "#         mask = (popt[:,:5] < 0) + (popt[:,:5] > Lmax - 1)\n",
    "#         popt[:,:5][mask] = torch.nan\n",
    "#         popt[:,5:][mask] = torch.nan\n",
    "#     return popt[:5]\n",
    "#     model = torch.load('./datasets/rsna-models/axial_T2_levels_1',map_location=torch.device(\"cpu\"))\n",
    "#     models = []\n",
    "#     for i in range(1,6):\n",
    "#         model = torch.load('./datasets/rsna-models/axial_T2_levels_'+str(i))\n",
    "#         models.append(model)\n",
    "#     merged_model = torch.nn.Sequential(*list(model[0].children()))\n",
    "#     for param_name, param in merged_model.named_parameters():\n",
    "#         param.data = (model1.state_dict()[param_name] + model2.state_dict()[param_name]) / 2\n",
    "#     model.eval()\n",
    "#  ---------------------------------------\n",
    "    models1 = []\n",
    "    models2 = []\n",
    "    for i in range(2,6):\n",
    "#         model = torch.load('./datasets/rsna-models/axial_T2_levels_'+str(i))\n",
    "        models1.append(torch.load('./datasets/rsna-models/axial_T2_levels_'+str(i)))\n",
    "    merged_model1 = torch.load('./datasets/rsna-models/axial_T2_levels_1')\n",
    "    for i in range(1,6):\n",
    "#         model = torch.load('./datasets/rsna-models/axial_T2_levels_'+str(i))\n",
    "        models2.append(torch.load('./datasets/final-axial-slice-calssifier/New_Axial_classifier_'+str(i)))\n",
    "    merged_model2 = torch.load('./datasets/final-axial-slice-calssifier/New_Axial_classifier_1')\n",
    "    for param_name, param in merged_model1.named_parameters():\n",
    "        for i in range(0,4):\n",
    "            param.data+=models1[i].state_dict()[param_name]\n",
    "        param.data/=4\n",
    "    for param_name, param in merged_model2.named_parameters():\n",
    "        for i in range(0,5):\n",
    "            param.data+=models2[i].state_dict()[param_name]\n",
    "        param.data/=5\n",
    "    merged_model1.eval()\n",
    "    merged_model2.eval()\n",
    "    levels0 = torch.argmax((merged_model1(X)+merged_model1(X.flip(1)).flip(-1)),-1).cpu().tolist()\n",
    "    levels1 = torch.argmax((merged_model2(X)+merged_model2(X.flip(1)).flip(-1)),-1).cpu().tolist()\n",
    "    return levels1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf3b42f51d4c7448"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RSNA24Dataset(Dataset):\n",
    "    def __init__(self, df,foraminal_unet,canal_unet,subarticular_unet,patch_size=128):\n",
    "        self.df = df\n",
    "        self.foraminal_unet = foraminal_unet\n",
    "        self.canal_unet = canal_unet\n",
    "        self.subarticular_unet = subarticular_unet\n",
    "        self.P = patch_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,index):\n",
    "        df = self.df.iloc[index]\n",
    "        study_id = df['study_id']\n",
    "        series_id = df['series_id']\n",
    "        series_description = df['series_description']\n",
    "        images = self.load_images(study_id,series_id)\n",
    "        sample = './datasets/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n",
    "#         sample = './datasets/rsna-lsdc-2024-submission-debug-dataset/debug/test_images/'\n",
    "        sample1 = sample + str(int(study_id)) +\"/\" +str(int(series_id)) +\"/\"\n",
    "        if series_description == \"Sagittal T1\":\n",
    "            images_and_mask_tensor = [] \n",
    "            for i in range(len(images)):\n",
    "                images_and_mask = get_image_for_canal_foraminal(sample1+str(i+1)+'.dcm',self.foraminal_unet,self.P,0.25)\n",
    "                condition = 0 if i<min(len(images)//2,10) else 1\n",
    "                images_and_mask+= [torch.tensor(condition)]\n",
    "                images_and_mask_tensor.append(images_and_mask)\n",
    "            final_item = []\n",
    "            final_item.append(images_and_mask_tensor)\n",
    "            final_item += [torch.tensor(study_id)]\n",
    "            final_item+=[torch.tensor(0)]\n",
    "            return final_item\n",
    "        elif series_description == \"Sagittal T2/STIR\":\n",
    "            images_and_mask_tensor = [] \n",
    "            for i in range(len(images)):\n",
    "                images_and_mask = get_image_for_canal_foraminal(sample1+str(i+1)+'.dcm',self.canal_unet,self.P,0.25)\n",
    "                images_and_mask_tensor.append(images_and_mask)\n",
    "            final_item = []\n",
    "            final_item.append(images_and_mask_tensor)\n",
    "            final_item += [torch.tensor(study_id)]\n",
    "            final_item+=[torch.tensor(1)]\n",
    "            return final_item\n",
    "        else:\n",
    "            coords,coords_mean = create_coords(self.subarticular_unet,images)\n",
    "            coords_left = []\n",
    "            coords_right = []\n",
    "            for j in range(0,len(coords),2):\n",
    "                coords_left.append(coords[j])\n",
    "                coords_right.append(coords[j+1])\n",
    "            left_images = get_images_for_axial_slice_labelling(coords_left,images)\n",
    "            right_images = get_images_for_axial_slice_labelling(coords_right,images)\n",
    "            left_levels = get_axial_slices(left_images)\n",
    "            right_levels = get_axial_slices(right_images)\n",
    "#             print(study_id,left_levels,right_levels)\n",
    "            left_images = left_images[left_levels]\n",
    "            right_images = right_images[right_levels]\n",
    "            return [torch.stack([left_images,right_images]),torch.tensor(study_id),torch.tensor(2)]\n",
    "        \n",
    "    def load_images(self,study_id,series_id):\n",
    "#         df = self.df[self.df['series_description']==self.series_desc]\n",
    "        sample = './datasets/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n",
    "#         sample = './datasets/rsna-lsdc-2024-submission-debug-dataset/debug/test_images/'\n",
    "        sample1 = sample + str(int(study_id)) +\"/\" +str(int(series_id)) +\"/\"\n",
    "        images = [x.replace('\\\\','/') for x in glob.glob(sample1+'*dcm')]\n",
    "        return images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e30dcd0f92d8d812"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "row_names = []\n",
    "final_preds = []\n",
    "conditions = {\n",
    "    0:\"Neural Foraminal Stenosis\",\n",
    "    1:\"Canal Stenosis\",\n",
    "    2:\"Subarticular Stenosis\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f72650c91e5849"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "funet = torch.load(\"./datasets/rsna-models/SEG_foraminal_1\")\n",
    "cunet = torch.load(\"./datasets/rsna-models/SEG_canal_1\")\n",
    "subunet = torch.load(\"./datasets/axial-models/SEG_subarticular_resnet34_1\")\n",
    "\n",
    "foraminalClassifier = torch.load(\"./datasets/rsna-models/ViT_1\")\n",
    "canalClassifierModels = [torch.load(\"./datasets/canal-classifier-models/Final_ViT_canal_\"+str(i)) for i in [1,3,4,5]]\n",
    "subarticularClassifier = torch.load(\"./datasets/axial-models/VIT_Axial_Classifier_1\")\n",
    "\n",
    "\n",
    "\n",
    "testdf = RSNA24Dataset(df,foraminal_unet=funet,canal_unet=cunet,subarticular_unet=subunet)\n",
    "testdl = torch.utils.data.DataLoader(testdf,batch_size=1,shuffle=False)\n",
    "with tqdm(testdl, leave=True) as pbar:\n",
    "    with torch.no_grad():\n",
    "        for idx, (x,stid,series_id) in enumerate(pbar):\n",
    "            series_desc = conditions[series_id.item()]\n",
    "            if series_desc == \"Neural Foraminal Stenosis\":\n",
    "                left_y_preds = np.zeros((5,3))\n",
    "                right_y_preds = np.zeros((5,3))\n",
    "                left_count=right_count=0\n",
    "                for data in x:\n",
    "                    i,m,ori = data\n",
    "                    i = i.to(device)\n",
    "                    m = m.to(device)\n",
    "                    pred_per_study = np.zeros((5, 3))\n",
    "                    preds = foraminalClassifier([i,m])\n",
    "        #             pred_mask = ~m.view(-1)\n",
    "                    if ori:\n",
    "                        for j in range(5):\n",
    "                            left_y_preds[j]+=np.array(torch.softmax(preds[j].cpu(),dim=0))\n",
    "                        left_count+=1\n",
    "                    else:\n",
    "                        for j in range(5):\n",
    "                            right_y_preds[j]+=np.array(torch.softmax(preds[j].cpu(),dim=0))\n",
    "                        right_count+=1\n",
    "                left_y_preds/=left_count\n",
    "                right_y_preds/=right_count\n",
    "                study_id = stid.item()\n",
    "                for i in range(2):\n",
    "                    for j in range(5):\n",
    "                        row_names.append(str(study_id)+\"_\"+NEURAL_FORAMINAL_CONDITION[i]+\"_\"+LEVELS[j])\n",
    "                final_preds.append(left_y_preds)\n",
    "                final_preds.append(right_y_preds)\n",
    "                del left_y_preds,x,right_y_preds,study_id,left_count,right_count\n",
    "                gc.collect()\n",
    "            elif series_desc == \"Canal Stenosis\":\n",
    "                canal_y_preds=np.zeros((5,3))\n",
    "                for data in x:\n",
    "                    i,m = data\n",
    "                    i = i.to(device)\n",
    "                    m = m.to(device)\n",
    "                    preds = torch.from_numpy(np.zeros((5,3))).to(device)\n",
    "                    for j in range(4):\n",
    "                        preds += canalClassifierModels[j]([i,m])\n",
    "                    preds/=4\n",
    "        #             pred_mask = ~m.view(-1)\n",
    "                    for j in range(5):\n",
    "                        canal_y_preds[j]+=np.array(torch.softmax(preds[j].cpu(),dim=0))    \n",
    "                canal_y_preds/=len(x)\n",
    "                study_id = stid.item()\n",
    "                for i in range(1):\n",
    "                    for j in range(5):\n",
    "                        row_names.append(str(study_id)+\"_\"+SPINAL_CANAL_CONDITION[i]+\"_\"+LEVELS[j])\n",
    "                final_preds.append(canal_y_preds)\n",
    "                del canal_y_preds,x,study_id\n",
    "                gc.collect()\n",
    "            else: \n",
    "                subarticular_y_preds=np.zeros((10,3))\n",
    "                x = x.view(-1,10,patch_size,patch_size)\n",
    "                x = x.to(device)\n",
    "                for j in range(10):\n",
    "                    preds = subarticularClassifier(x[0][j])\n",
    "                    subarticular_y_preds[j]+=np.array(torch.softmax(preds[0].cpu(),dim=0))          \n",
    "                study_id=stid.item()\n",
    "                for i in range(2):\n",
    "                    for j in range(5):\n",
    "                        row_names.append(str(study_id)+\"_\"+SUBARTICULAR_CONDITIONS[i]+\"_\"+LEVELS[j])\n",
    "                final_preds.append(subarticular_y_preds)\n",
    "                del subarticular_y_preds,study_id\n",
    "                gc.collect()\n",
    "                \n",
    "del funet,cunet,subunet,foraminalClassifier,canalClassifierModels,subarticularClassifier\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3918190b9ac33771"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_preds = np.concatenate(final_preds,axis=0)\n",
    "sub = pd.DataFrame()\n",
    "sub['row_id'] = row_names\n",
    "sub[LABELS] = final_preds\n",
    "sub.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c0f70b559cb1bdd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sub = sub.groupby('row_id').mean()\n",
    "sub = sub.reset_index()\n",
    "sub.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2344ab5bfb2f511"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sub.to_csv('./datasets/submission.csv', index=False)\n",
    "pd.read_csv('./datasets/working/submission.csv').head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72904d3934813199"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
